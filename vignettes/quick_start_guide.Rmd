---
title: "clustOpt: Quickstart Guide"
output:
  html_document:
    theme: united
    df_print: kable
  pdf_document: default
date: 'Compiled: `r Sys.Date()`'
vignette: >
  %\VignetteIndexEntry{clustOpt: Quickstart Guide}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, warning=FALSE, echo=FALSE}
library(Seurat)
# Only v5 Seurat Assays are supported
options(Seurat.object.assay.version = "v5")
# Only needs to be set for analyzing large datasets
options(future.globals.maxSize = 1e9)
library(dplyr)
library(clustOpt)
library(foreach)
library(doFuture)
set.seed(1)
```

```{r load_data}
# Read in a leverage score based subsample (1% of total cells) of the AIDA dataset
input <- readRDS("../inst/extdata/10589_cells_AIDA.rds")

input <- input |>
  SCTransform(vst.flavor = "v2", verbose = FALSE) |>
  RunPCA(verbose = FALSE)
```

```{r data_summary}

  
```


```{r elbowplot}
ElbowPlot(input)
```

```{r UMAP, fig.width=15, warning=FALSE}
input <- RunUMAP(input,dims = 1:10)

DimPlot(input, group.by = "cell_type",
        label = TRUE,
        label.box = TRUE,
        repel = TRUE,
        pt.size = .2)
```

The leverage score based subsample (sketch) of 1% cells captures a surprisingly large amount of the variation between cell types.

```{r, fig.width=15}
DimPlot(input,
        group.by = "self_reported_ethnicity",
        split.by = "self_reported_ethnicity",
        order = T,
        pt.size = .5,
        alpha = .5) +
  NoLegend()
```



```{r}

registerDoFuture()
tmp <- clust_opt(input,
                 res_range = c(.01,.1),
                 subject_ids = "self_reported_ethnicity",
                 plan = "multisession",
                 ndim = 10,
                 ncore = 4,
                 verbose = T)


common_features <- intersect(
    rownames(test@assays[["SCT"]]@scale.data),
    VariableFeatures(train))
# Extract the loadings for common features from the training data
loadings_common_features <- Loadings(train[["pca"]]) %>%
  as_tibble(rownames = "Features") %>%
  filter(Features %in% common_features) %>%
  as.matrix()

rownames(loadings_common_features) <- loadings_common_features[, 1]
loadings_common_features <- loadings_common_features[, -1]
class(loadings_common_features) <- "numeric"
  
pca_train_data <- as.matrix(train[["SCT"]]@scale.data)[common_features, ] %>%
    t() %*% loadings_common_features

# Project the cells in the test data onto the PCs
# identified using the training data
pca_test_data <- as.matrix(test[["SCT"]]@scale.data)[common_features, ] %>%
    t() %*% loadings_common_features

train <- tmp[[1]] 
test <- tmp[[2]] 
tmp[[1]]@assays$SCT$scale.data |> useful::corner()

```

